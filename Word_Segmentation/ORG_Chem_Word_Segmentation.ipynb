{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ORG_Chem_Word_Segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "Python 3.8.5 64-bit",
      "display_name": "Python 3.8.5 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3OfNRQA3Gt8",
        "colab_type": "text"
      },
      "source": [
        "# Import Character Vocab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOlG2SQfrlOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import tensorflow as tf"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq7h6WJTs89M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('files/vocab.json', 'r') as f:\n",
        "  CHAR_INDICES = json.load(f)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKdOILCutjVM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ec10e396-e3e8-486a-dd5b-1b6f070919c5",
        "tags": []
      },
      "source": [
        "print(CHAR_INDICES)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{' ': 0, '(': 1, ')': 2, ',': 3, '-': 4, '0': 5, '1': 6, '2': 7, '3': 8, '4': 9, '5': 10, '6': 11, '7': 12, '8': 13, '9': 14, 'A': 15, 'B': 16, 'C': 17, 'D': 18, 'E': 19, 'F': 20, 'G': 21, 'H': 22, 'I': 23, 'J': 24, 'K': 25, 'L': 26, 'M': 27, 'N': 28, 'O': 29, 'P': 30, 'Q': 31, 'R': 32, 'S': 33, 'T': 34, 'U': 35, 'V': 36, 'W': 37, 'X': 38, 'Y': 39, 'Z': 40, 'a': 41, 'b': 42, 'c': 43, 'd': 44, 'e': 45, 'f': 46, 'g': 47, 'h': 48, 'i': 49, 'j': 50, 'k': 51, 'l': 52, 'm': 53, 'n': 54, 'o': 55, 'p': 56, 'q': 57, 'r': 58, 's': 59, 't': 60, 'u': 61, 'v': 62, 'w': 63, 'x': 64, 'y': 65, 'z': 66, '<pad>': 67, '<unk>': 68}\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGUQS25OVJIJ",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN2uPnKJdr0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "look_back = 10"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYP03g3TrMXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(text, look_back = look_back):\n",
        "  \"\"\"\n",
        "  take text with label (text that being defined where to cut ('|')) \n",
        "  and encode text and make label\n",
        "  return encoded text & label\n",
        "  \"\"\"\n",
        "  X, y = [], []\n",
        "  text = '|' + text\n",
        "  data = [CHAR_INDICES['<pad>']] * look_back\n",
        "  for i in range(1, len(text)):\n",
        "    current_char = text[i]\n",
        "    before_char = text[i-1]\n",
        "\n",
        "    if current_char == '|':\n",
        "      continue\n",
        "    data = data[1:] + [CHAR_INDICES[current_char]]  # X data\n",
        "\n",
        "    target = 1 if before_char == '|' else 0  # y data\n",
        "    X.append(data)\n",
        "    y.append(target)\n",
        "  \n",
        "  return np.array(X), tf.one_hot(y, 2)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhL81QrDazGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_pred_preprocessing(text, sequence_len=10):\n",
        "  \"\"\"\n",
        "    take unseen (testing) text and encode it with CHAR_DICT\n",
        "    //It's like create_dataset() but not return label\n",
        "    return encoded text\n",
        "  \"\"\"\n",
        "  X = []\n",
        "  data = [CHAR_INDICES['<pad>']] * sequence_len\n",
        "  for char in text:\n",
        "    char = char if char in CHAR_INDICES else '<unk>'  # check char in dictionary\n",
        "    data = data[1:] + [CHAR_INDICES[char]]  # X data\n",
        "    X.append(data)\n",
        "  return np.array(X)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98YuegoQyZvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_tokenize(text, class_):\n",
        "    cut_indexs = []\n",
        "    words = []\n",
        "\n",
        "    # boolean index of each word 1 if cut before\n",
        "    class_ = np.append(class_, 1)\n",
        "\n",
        "    # if y_label at i is 1 so add i (index) to cut_indexs\n",
        "    for i, value in enumerate(class_):\n",
        "      if value == 1:\n",
        "        cut_indexs.append(i)\n",
        "\n",
        "    # add word after cutting till before ext cutting\n",
        "    for i in range(len(cut_indexs)-1):\n",
        "      words.append(text[cut_indexs[i]:cut_indexs[i+1]])\n",
        "    \n",
        "    return words"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decode_label(y):\n",
        "  return tf.argmax(y, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHyGGAJyz7FM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('files/Dictionary.json', 'r') as f1, open('files/Dictionary_cut.json', 'r') as f2:\n",
        "    Dict = json.load(f1)\n",
        "    Dict_cut = json.load(f2)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRbRE5NFtfcE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "3bc9cf04-0bc1-41d6-f428-33d77152ef66",
        "tags": []
      },
      "source": [
        "for key, value in Dict.items():\n",
        "    print(key, len(value))\n",
        "print('-'*15)\n",
        "for key, value in Dict_cut.items():\n",
        "    print(key, len(value))\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "alkane 10\nalkane_alkyl 30\ncyclo_alkane 8\ncyclo_alkane_alkyl 17\nalkene 25\nalkene_alkyl 15\ndialkene 69\ncyclo_alkene 8\ncyclo_alkene_alkyl 3\nalkyne 9\nalkyne_alkyl 9\ndialkyne 49\ncyclo_alkyne 8\n---------------\nalkane 10\nalkane_alkyl 30\ncyclo_alkane 8\ncyclo_alkane_alkyl 17\nalkene 25\nalkene_alkyl 15\ndialkene 69\ncyclo_alkene 8\ncyclo_alkene_alkyl 3\nalkyne 9\nalkyne_alkyl 9\ndialkyne 49\ncyclo_alkyne 8\n<built-in method keys of dict object at 0x7f67240ec6c0>\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "key Dict: 13\nket Dict_cut: 13\n"
        }
      ],
      "source": [
        "print('key Dict:',len(Dict.keys()))\n",
        "print('ket Dict_cut:',len(Dict_cut.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YStOZHdVPt1",
        "colab_type": "text"
      },
      "source": [
        "# Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTllUAldU6Sk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea867dda-33b6-43e1-d9ba-e1c087a78c31",
        "tags": []
      },
      "source": [
        "last_key = list(Dict.keys())[-1]\n",
        "print(last_key)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "cyclo_alkyne\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jUhDMYLT45h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "4ba291fe-96a8-4a8a-dbd4-b33654f0ca79",
        "tags": []
      },
      "source": [
        "dataset_cut = ''\n",
        "for key, value in Dict_cut.items():\n",
        "    for name in value:\n",
        "        dataset_cut += name\n",
        "        if name != Dict_cut[last_key][-1]:\n",
        "            dataset_cut = dataset_cut + '| |'\n",
        "    #print(len(dataset_cut.replace('|','')))\n",
        "print(dataset_cut[:101])\n",
        "print(len(dataset_cut.replace('|','')))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Meth|ane| |Eth|ane| |Prop|ane| |But|ane| |Pent|ane| |Hex|ane| |Hept|ane| |Oct|ane| |Non|ane| |Dec|ane\n4155\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NiWUZwKUnqY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "1102a7d4-d35b-41ab-8fff-22226b333c93",
        "tags": []
      },
      "source": [
        "dataset = \"\"\n",
        "for key, value in Dict.items():\n",
        "  for name in value:\n",
        "    dataset += name\n",
        "    if name != Dict[last_key][-1]:\n",
        "      dataset = dataset + ' '\n",
        "  #print(len(dataset.replace('|','')))\n",
        "print(dataset[:73])\n",
        "print(len(dataset))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Methane Ethane Propane Butane Pentane Hexane Heptane Octane Nonane Decane\n4155\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2afRpduVvog",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "99dde2e2-2f18-41f8-99dc-61b82193a5cf",
        "tags": []
      },
      "source": [
        "X_train, y = create_dataset(dataset_cut)\n",
        "print(y.numpy())\n",
        "\n",
        "X_test = text_pred_preprocessing(dataset)\n",
        "print(X_train.shape, y.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[[0. 1.]\n [1. 0.]\n [1. 0.]\n ...\n [0. 1.]\n [1. 0.]\n [1. 0.]]\n(4155, 10) (4155, 2)\n(4155, 10)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLZO-FPGlzz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = tf.data.Dataset.from_tensor_slices((X_train,y))\n",
        "training_data = training_data.batch(128)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SxmThNeVVg4",
        "colab_type": "text"
      },
      "source": [
        "# Create Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GK3s02l336w",
        "colab_type": "text"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yecuD8XIVXVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Embedding\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLVuON-cdnSQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89e1a22c-8454-4195-a0cc-7f63d5cd6cc4",
        "tags": []
      },
      "source": [
        "_input_shape = (look_back, len(CHAR_INDICES))\n",
        "print(_input_shape[1])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "69\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0jAOIBzdDYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Model = Sequential(\n",
        "    [\n",
        "     Embedding(len(CHAR_INDICES), _input_shape[1]),\n",
        "     Bidirectional(LSTM(_input_shape[1]//2, return_sequences=False),\n",
        "                      merge_mode='sum',\n",
        "                      weights=None),\n",
        "     Dense(_input_shape[1]//4),\n",
        "     Dense(2, activation='softmax')\n",
        "    ],\n",
        "    name='model'\n",
        ")"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WifMOz_Kextr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "ac120972-913b-4f31-9938-c6620c1bbf68",
        "tags": []
      },
      "source": [
        "Model.summary()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_2 (Embedding)      (None, None, 69)          4761      \n_________________________________________________________________\nbidirectional_2 (Bidirection (None, 34)                28288     \n_________________________________________________________________\ndense_4 (Dense)              (None, 17)                595       \n_________________________________________________________________\ndense_5 (Dense)              (None, 2)                 36        \n=================================================================\nTotal params: 33,680\nTrainable params: 33,680\nNon-trainable params: 0\n_________________________________________________________________\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNzpxjEb38LI",
        "colab_type": "text"
      },
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXJ10S4MfBgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "33d88c5d-4351-4787-8f96-a291631be310",
        "tags": []
      },
      "source": [
        "Model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "Model.fit(training_data, epochs=10)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/10\n33/33 [==============================] - 0s 6ms/step - loss: 0.6472 - accuracy: 0.6103\nEpoch 2/10\n33/33 [==============================] - 0s 8ms/step - loss: 0.4532 - accuracy: 0.7690\nEpoch 3/10\n33/33 [==============================] - 0s 6ms/step - loss: 0.2734 - accuracy: 0.9025\nEpoch 4/10\n33/33 [==============================] - 0s 7ms/step - loss: 0.1934 - accuracy: 0.9266\nEpoch 5/10\n33/33 [==============================] - 0s 7ms/step - loss: 0.1506 - accuracy: 0.9439\nEpoch 6/10\n33/33 [==============================] - 0s 6ms/step - loss: 0.1117 - accuracy: 0.9598\nEpoch 7/10\n33/33 [==============================] - 0s 6ms/step - loss: 0.0909 - accuracy: 0.9706\nEpoch 8/10\n33/33 [==============================] - 0s 6ms/step - loss: 0.0724 - accuracy: 0.9781\nEpoch 9/10\n33/33 [==============================] - 0s 7ms/step - loss: 0.0605 - accuracy: 0.9793\nEpoch 10/10\n33/33 [==============================] - 0s 8ms/step - loss: 0.0513 - accuracy: 0.9819\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f66e45a5f40>"
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ku7X6OamroD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "9d05974e-6a6a-42e0-83f8-2cb61ce980df",
        "tags": []
      },
      "source": [
        "pred_proba = Model.predict(X_test)\n",
        "print(pred_proba.round(3))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[[0.002 0.998]\n [0.991 0.009]\n [1.    0.   ]\n ...\n [0.393 0.607]\n [0.999 0.001]\n [0.984 0.016]]\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osFEsCKcqxYv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "45ad5fdc-15fc-4898-e687-36f1f8142084",
        "tags": []
      },
      "source": [
        "pred = decode_label(pred_proba)\n",
        "y_decode = decode_label(y)\n",
        "\n",
        "print(\"true:\", y_decode)\n",
        "print(\"predict:\",pred)\n",
        "print(\"y:\",y_decode.shape,\"ans:\",pred.shape)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "true: [1 0 0 ... 1 0 0]\npredict: [1 0 0 ... 1 0 0]\ny: (4155,) ans: (4155,)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q21LstY_rRNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "4adfde83-ec4a-46b5-97fc-64b1d20a277b",
        "tags": []
      },
      "source": [
        "# Count same item between y (label) and pred (prediction)\n",
        "elem_same = (y_decode == pred).sum()\n",
        "\n",
        "print(\"Same =\",elem_same,\", Not Same =\",pred.shape[0]-elem_same)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(tf.math.confusion_matrix(y_decode, pred, num_classes=2).numpy())"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Same = 4098 , Not Same = 57\n\nConfusion Matrix:\n[[1842   15]\n [  42 2256]]\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPG4YEdh4AiH",
        "colab_type": "text"
      },
      "source": [
        "## Test on unseen data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KsMjtRetqLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "myText = \"Benzyl-N,2-dimethylpentan-3-aminoate\"\n",
        "myText_cut = \"Benz|yl|-|N|,|2|-|di|meth|yl|pent|an|-|3|-|amin|oate\""
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWj1_5XS30p_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "29d2c419-abe0-40a5-f6d0-09c7a7d01fe3",
        "tags": []
      },
      "source": [
        "myText_test, my_y = create_dataset(myText_cut)\n",
        "\n",
        "pred_test_proba = Model.predict(myText_test)\n",
        "\n",
        "pred_test = decode_label(pred_test_proba)\n",
        "my_y_decode = decode_label(my_y)\n",
        "\n",
        "print(pred_test)\n",
        "print(my_y_decode)\n",
        "\n",
        "# Count same item between y (label) and pred (prediction)\n",
        "elem_same = (pred_test == my_y_decode).sum()\n",
        "print(\"\\nSame =\",elem_same,\", Not Same =\",pred_test.shape[0]-elem_same)\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(tf.math.confusion_matrix(my_y_decode, pred_test, num_classes=2).numpy())"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[1 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0]\n[1 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 0 0 1 0 0 0]\n\nSame = 32 , Not Same = 4\n\nConfusion Matrix:\n[[17  2]\n [ 2 15]]\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiGlram741Ne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "207ecdc7-48d0-4237-c9ed-8037944b4424",
        "tags": []
      },
      "source": [
        "words = word_tokenize(myText, pred_test)\n",
        "print(words)\n",
        "print('|'.join(words))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['Benzyl', '-', 'N', ',', '2', '-', 'di', 'meth', 'yl', 'pent', 'an', '-', '3', '-', 'a', 'mino', 'ate']\nBenzyl|-|N|,|2|-|di|meth|yl|pent|an|-|3|-|a|mino|ate\n"
        }
      ]
    }
  ]
}