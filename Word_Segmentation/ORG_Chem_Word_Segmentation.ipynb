{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3OfNRQA3Gt8"
   },
   "source": [
    "# Import Character Vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WOlG2SQfrlOw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-25 16:09:02.758683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-25 16:09:02.775746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-25 16:09:02.776098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Yq7h6WJTs89M",
    "outputId": "1030b00a-bffd-4b49-d302-be9db7b202c8"
   },
   "outputs": [],
   "source": [
    "with open('files/vocab.json', 'r') as f:\r\n",
    "  CHAR_INDICES = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "iKdOILCutjVM",
    "outputId": "b5739165-d224-43fd-a4e3-a313f95f8fa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '(': 1, ')': 2, ',': 3, '-': 4, '0': 5, '1': 6, '2': 7, '3': 8, '4': 9, '5': 10, '6': 11, '7': 12, '8': 13, '9': 14, 'A': 15, 'B': 16, 'C': 17, 'D': 18, 'E': 19, 'F': 20, 'G': 21, 'H': 22, 'I': 23, 'J': 24, 'K': 25, 'L': 26, 'M': 27, 'N': 28, 'O': 29, 'P': 30, 'Q': 31, 'R': 32, 'S': 33, 'T': 34, 'U': 35, 'V': 36, 'W': 37, 'X': 38, 'Y': 39, 'Z': 40, 'a': 41, 'b': 42, 'c': 43, 'd': 44, 'e': 45, 'f': 46, 'g': 47, 'h': 48, 'i': 49, 'j': 50, 'k': 51, 'l': 52, 'm': 53, 'n': 54, 'o': 55, 'p': 56, 'q': 57, 'r': 58, 's': 59, 't': 60, 'u': 61, 'v': 62, 'w': 63, 'x': 64, 'y': 65, 'z': 66, '<pad>': 67, '<unk>': 68}\n"
     ]
    }
   ],
   "source": [
    "print(CHAR_INDICES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGUQS25OVJIJ"
   },
   "source": [
    "# Preprocessing text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsUEAfwPiMj1"
   },
   "source": [
    "## look_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IN2uPnKJdr0h"
   },
   "outputs": [],
   "source": [
    "look_back = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wYP03g3TrMXb"
   },
   "outputs": [],
   "source": [
    "def create_dataset(text, look_back = look_back):\n",
    "\n",
    "  \"\"\"\n",
    "  take text with label (text that being defined where to cut ('|')) \n",
    "  and encode text and make label\n",
    "  return preprocessed text & preprocessed label\n",
    "  \"\"\"\n",
    "  X, y = [], []\n",
    "  text = '|' + text\n",
    "  data = [CHAR_INDICES['<pad>']] * look_back\n",
    "  for i in range(1, len(text)):\n",
    "    current_char = text[i]\n",
    "    before_char = text[i-1]\n",
    "\n",
    "    if current_char == '|':\n",
    "      continue\n",
    "    data = data[1:] + [CHAR_INDICES[current_char]]  # X data\n",
    "\n",
    "    target = 1 if before_char == '|' else 0  # y data\n",
    "    X.append(data)\n",
    "    y.append(target)\n",
    "  \n",
    "  return np.array(X), tf.one_hot(y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LhL81QrDazGn"
   },
   "outputs": [],
   "source": [
    "def text_pred_preprocessing(text, sequence_len=look_back):\n",
    "  \"\"\"\n",
    "    take unseen (testing) text and encode it with CHAR_DICT\n",
    "    //It's like create_dataset() but not return label\n",
    "    return preprocessed text\n",
    "  \"\"\"\n",
    "  X = []\n",
    "  data = [CHAR_INDICES['<pad>']] * sequence_len\n",
    "  for char in text:\n",
    "    char = char if char in CHAR_INDICES else '<unk>'  # check char in dictionary\n",
    "    data = data[1:] + [CHAR_INDICES[char]]  # X data\n",
    "    X.append(data)\n",
    "  return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "98YuegoQyZvQ"
   },
   "outputs": [],
   "source": [
    "def word_tokenize(text, class_):\n",
    "    cut_indexs = []\n",
    "    words = []\n",
    "\n",
    "    # boolean index of each word 1 if cut before\n",
    "    class_ = np.append(class_, 1)\n",
    "\n",
    "    # if y_label at i is 1 so add i (index) to cut_indexs\n",
    "    for i, value in enumerate(class_):\n",
    "      if value == 1:\n",
    "        cut_indexs.append(i)\n",
    "\n",
    "    # add word after cutting till before ext cutting\n",
    "    for i in range(len(cut_indexs)-1):\n",
    "      words.append(text[cut_indexs[i]:cut_indexs[i+1]])\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uaKNlRBTNtwy"
   },
   "outputs": [],
   "source": [
    "def decode_label(y):\n",
    "  return tf.argmax(y, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqK1KQFO2SgX"
   },
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    index        cid                                          iupacname  \\\n0  292494    2737317                        2-fluoroethyl prop-2-enoate   \n1   66839  101800358   diethyl (Z)-2-ethyl-3-prop-2-enylbut-2-enedioate   \n2  256207     230278                     ethyl 2-cyano-2-nitrosoacetate   \n3  233531   12452091                     trimethylsilyl 4-aminobenzoate   \n4  165414   14657217  ethyl 2-[[(Z)-3-methyl-4-oxopent-2-en-2-yl]ami...   \n\n                                               label     file_names  \n0             2|-|fluoro|eth|yl| |prop|-|2|-|en|oate    2737317.png  \n1  di|eth|yl| |(|Z|)|-|2|-|eth|yl|-|3|-|prop|-|2|...  101800358.png  \n2          eth|yl| |2|-|cyano|-|2|-|nitroso|acet|ate     230278.png  \n3            trimeth|yl|sil|yl| |4|-|amino|benz|oate   12452091.png  \n4  eth|yl| |2|-|[|[|(|Z|)|-|3|-|meth|yl|-|4|-|oxo...   14657217.png  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>cid</th>\n      <th>iupacname</th>\n      <th>label</th>\n      <th>file_names</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>292494</td>\n      <td>2737317</td>\n      <td>2-fluoroethyl prop-2-enoate</td>\n      <td>2|-|fluoro|eth|yl| |prop|-|2|-|en|oate</td>\n      <td>2737317.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>66839</td>\n      <td>101800358</td>\n      <td>diethyl (Z)-2-ethyl-3-prop-2-enylbut-2-enedioate</td>\n      <td>di|eth|yl| |(|Z|)|-|2|-|eth|yl|-|3|-|prop|-|2|...</td>\n      <td>101800358.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>256207</td>\n      <td>230278</td>\n      <td>ethyl 2-cyano-2-nitrosoacetate</td>\n      <td>eth|yl| |2|-|cyano|-|2|-|nitroso|acet|ate</td>\n      <td>230278.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>233531</td>\n      <td>12452091</td>\n      <td>trimethylsilyl 4-aminobenzoate</td>\n      <td>trimeth|yl|sil|yl| |4|-|amino|benz|oate</td>\n      <td>12452091.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>165414</td>\n      <td>14657217</td>\n      <td>ethyl 2-[[(Z)-3-methyl-4-oxopent-2-en-2-yl]ami...</td>\n      <td>eth|yl| |2|-|[|[|(|Z|)|-|3|-|meth|yl|-|4|-|oxo...</td>\n      <td>14657217.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../Making_Datasets/dataframe/df_train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    index        cid                                          iupacname  \\\n0  216886  102476271  methyl (2R,3R)-2-amino-3-hydroxy-3-(3-methylph...   \n1  196002   57375822        tert-butyl 2-amino-3-pyridin-3-ylpropanoate   \n2  170094   16099663   ethyl 3-methyl-2-oxocyclohex-3-ene-1-carboxylate   \n3  291564   93972463                  methyl (2S)-2-hydroxybut-3-enoate   \n4  273267      85736                          butan-2-yl 2-cyanoacetate   \n\n                                               label     file_names  \n0  meth|yl| |(|2|R|,|3|R|)|-|2|-|amino|-|3|-|hydr...  102476271.png  \n1  tert|-|but|yl| |2|-|amino|-|3|-|pyridin|-|3|-|...   57375822.png  \n2  eth|yl| |3|-|meth|yl|-|2|-|oxo|cyclo|hex|-|3|-...   16099663.png  \n3   meth|yl| |(|2S|)|-|2|-|hydroxy|but|-|3|-|en|oate   93972463.png  \n4               but|an|-|2|-|yl| |2|-|cyano|acet|ate      85736.png  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>cid</th>\n      <th>iupacname</th>\n      <th>label</th>\n      <th>file_names</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>216886</td>\n      <td>102476271</td>\n      <td>methyl (2R,3R)-2-amino-3-hydroxy-3-(3-methylph...</td>\n      <td>meth|yl| |(|2|R|,|3|R|)|-|2|-|amino|-|3|-|hydr...</td>\n      <td>102476271.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>196002</td>\n      <td>57375822</td>\n      <td>tert-butyl 2-amino-3-pyridin-3-ylpropanoate</td>\n      <td>tert|-|but|yl| |2|-|amino|-|3|-|pyridin|-|3|-|...</td>\n      <td>57375822.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>170094</td>\n      <td>16099663</td>\n      <td>ethyl 3-methyl-2-oxocyclohex-3-ene-1-carboxylate</td>\n      <td>eth|yl| |3|-|meth|yl|-|2|-|oxo|cyclo|hex|-|3|-...</td>\n      <td>16099663.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>291564</td>\n      <td>93972463</td>\n      <td>methyl (2S)-2-hydroxybut-3-enoate</td>\n      <td>meth|yl| |(|2S|)|-|2|-|hydroxy|but|-|3|-|en|oate</td>\n      <td>93972463.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>273267</td>\n      <td>85736</td>\n      <td>butan-2-yl 2-cyanoacetate</td>\n      <td>but|an|-|2|-|yl| |2|-|cyano|acet|ate</td>\n      <td>85736.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.read_csv('../Making_Datasets/dataframe/df_val.csv')\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    index        cid                                          iupacname  \\\n0  207012   86636857               (3-methyloxan-4-yl) methanesulfonate   \n1    4342  102037167  methyl (2R,4R)-2-cyano-4-phenyl-2-propan-2-ylp...   \n2   88871   24813332  tert-butyl N-hydroxy-N-(3-methyl-1-thiophen-2-...   \n3   76746   22093490  methyl 4-fluoro-2-methoxy-5-morpholin-4-ylbenz...   \n4  284462  100974435              [(3S)-hex-1-en-3-yl] methyl carbonate   \n\n                                               label     file_names  \n0  (|3|-|meth|yl|oxan|-|4|-|yl|)| |meth|ane|sulfo...   86636857.png  \n1  meth|yl| |(|2|R|,|4|R|)|-|2|-|cyano|-|4|-|phen...  102037167.png  \n2  tert|-|but|yl| |N|-|hydroxy|-|N|-|(|3|-|meth|y...   24813332.png  \n3  meth|yl| |4|-|fluoro|-|2|-|meth|oxy|-|5|-|morp...   22093490.png  \n4  [|(|3S|)|-|hex|-|1|-|en|-|3|-|yl|]| |meth|yl| ...  100974435.png  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>cid</th>\n      <th>iupacname</th>\n      <th>label</th>\n      <th>file_names</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>207012</td>\n      <td>86636857</td>\n      <td>(3-methyloxan-4-yl) methanesulfonate</td>\n      <td>(|3|-|meth|yl|oxan|-|4|-|yl|)| |meth|ane|sulfo...</td>\n      <td>86636857.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4342</td>\n      <td>102037167</td>\n      <td>methyl (2R,4R)-2-cyano-4-phenyl-2-propan-2-ylp...</td>\n      <td>meth|yl| |(|2|R|,|4|R|)|-|2|-|cyano|-|4|-|phen...</td>\n      <td>102037167.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>88871</td>\n      <td>24813332</td>\n      <td>tert-butyl N-hydroxy-N-(3-methyl-1-thiophen-2-...</td>\n      <td>tert|-|but|yl| |N|-|hydroxy|-|N|-|(|3|-|meth|y...</td>\n      <td>24813332.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>76746</td>\n      <td>22093490</td>\n      <td>methyl 4-fluoro-2-methoxy-5-morpholin-4-ylbenz...</td>\n      <td>meth|yl| |4|-|fluoro|-|2|-|meth|oxy|-|5|-|morp...</td>\n      <td>22093490.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>284462</td>\n      <td>100974435</td>\n      <td>[(3S)-hex-1-en-3-yl] methyl carbonate</td>\n      <td>[|(|3S|)|-|hex|-|1|-|en|-|3|-|yl|]| |meth|yl| ...</td>\n      <td>100974435.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test= pd.read_csv('../Making_Datasets/dataframe/df_test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_dataset(arr_iupac, arr_label):\n",
    "  return ' '.join(arr_iupac), '|'.join(arr_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-fluoroet ++ 2|-|fluoro|eth|yl| |\n",
      "methyl (2R ++ meth|yl| |(|2|R|,|3|\n",
      "(3-methylo ++ (|3|-|meth|yl|oxan|-\n"
     ]
    }
   ],
   "source": [
    "text_train, text_cut_train = prepare_text_dataset(df_train['iupacname'].values, df_train['label'].values)\n",
    "text_val, text_cut_val = prepare_text_dataset(df_val['iupacname'].values, df_val['label'].values)\n",
    "text_test, text_cut_test = prepare_text_dataset(df_test['iupacname'].values, df_test['label'].values)\n",
    "\n",
    "print(text_train[:10], '++', text_cut_train[:20])\n",
    "print(text_val[:10], '++', text_cut_val[:20])\n",
    "print(text_test[:10], '++', text_cut_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "u2afRpduVvog",
    "outputId": "8172ad0e-56d0-4238-80a0-f9bce2847802"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'['",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_7291/1618528080.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mX_train\u001B[0m \u001B[0;34m,\u001B[0m\u001B[0my_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext_cut_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mX_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_val\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext_cut_val\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mX_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_test\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext_cut_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_7291/3017232896.py\u001B[0m in \u001B[0;36mcreate_dataset\u001B[0;34m(text, look_back)\u001B[0m\n\u001B[1;32m     15\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mcurrent_char\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'|'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m       \u001B[0;32mcontinue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m     \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mCHAR_INDICES\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcurrent_char\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m  \u001B[0;31m# X data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0mtarget\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mbefore_char\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'|'\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;36m0\u001B[0m  \u001B[0;31m# y data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: '['"
     ]
    }
   ],
   "source": [
    "X_train ,y_train = create_dataset(text_cut_train)\n",
    "X_val, y_val = create_dataset(text_cut_val)\n",
    "X_test, y_test = create_dataset(text_cut_test)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLZO-FPGlzz_"
   },
   "outputs": [],
   "source": [
    "training_data = tf.data.Dataset.from_tensor_slices((tf.cast(X_train, tf.float32),y_train))\n",
    "training_data = training_data.shuffle(222623).batch(128).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "validation_data = tf.data.Dataset.from_tensor_slices((tf.cast(X_val, tf.float32), y_val))\n",
    "validation_data = validation_data.shuffle(47381).batch(128).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "testing_data = tf.data.Dataset.from_tensor_slices((tf.cast(X_test, tf.float32), y_test))\n",
    "testing_data = testing_data.shuffle(48552).batch(128).cache().prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SxmThNeVVg4"
   },
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GK3s02l336w"
   },
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yecuD8XIVXVn"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Embedding, GRU, Dropout, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ZLVuON-cdnSQ",
    "outputId": "b951da14-6d76-4c79-e349-13aa023e4b6f"
   },
   "outputs": [],
   "source": [
    "_input_shape = (look_back, len(CHAR_INDICES))\n",
    "print(_input_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0jAOIBzdDYJ"
   },
   "outputs": [],
   "source": [
    "Model = Sequential(\n",
    "    [\n",
    "    tf.keras.layers.Input((look_back,), dtype=tf.float16),\n",
    "    Embedding(len(CHAR_INDICES), 64, input_length= look_back),\n",
    "\n",
    "    #Conv1D(filters=64, kernel_size=5, padding='same', activation='relu'),\n",
    "    #MaxPooling1D(pool_size=2),\n",
    "     \n",
    "    Bidirectional(GRU(32, return_sequences=False), merge_mode='sum'),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Dense(2, activation='softmax'),\n",
    "    tf.keras.layers.Activation('softmax', dtype=tf.float32)\n",
    "    ],\n",
    "    name='model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "WifMOz_Kextr",
    "outputId": "d039b7a6-3db3-467e-cc2a-63cf6c79df72"
   },
   "outputs": [],
   "source": [
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(Model, to_file='model.png', show_shapes=True, dpi=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNzpxjEb38LI"
   },
   "source": [
    "## Training Model (with callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking Bi-GRU\n",
    "## (9s) loss: 0.3269 - accuracy: 0.9988 - val_loss: 0.3287 - val_accuracy: 0.9974\n",
    "\n",
    "# Bi-GRU\n",
    "## (7s) loss: 0.3277 - accuracy: 0.9982 - val_loss: 0.3292 - val_accuracy: 0.9970\n",
    "\n",
    "# Stacking Bi-LSTM\n",
    "## (9s) loss: 0.3269 - accuracy: 0.9988 - val_loss: 0.3290 - val_accuracy: 0.9974\n",
    "\n",
    "# Bi-LSTM\n",
    "## (6s) loss: 0.3280 - accuracy: 0.9981 - val_loss: 0.3297 - val_accuracy: 0.9968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uXJ10S4MfBgN",
    "outputId": "57e4935d-f7a7-4829-e67f-bdd183ddae97"
   },
   "outputs": [],
   "source": [
    "Model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss= tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.2),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "checkpoint_path = 'save_models/best_model.hdf5'\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    include_optimizer=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=0,\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=5,\n",
    "    verbose=1, restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "\n",
    "callback_list = [earlystop_callback, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = Model.fit(training_data, validation_data=validation_data, epochs=100, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = create_dataset(text_cut_test)\n",
    "print(y_test.shape)\n",
    "\n",
    "Model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8DssGfR2LKG"
   },
   "source": [
    "##  Plot loss function and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "W5wd1CJWscCl",
    "outputId": "66842ba9-2cf2-4734-f849-0cb70a1d55a7"
   },
   "outputs": [],
   "source": [
    "print(type(history.history))\n",
    "print(history.history.keys())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['loss'], label='training_loss')\n",
    "plt.plot(history.history['val_loss'], label='validation_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='training_acc')\n",
    "plt.plot(history.history['val_accuracy'], label='validation_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPG4YEdh4AiH"
   },
   "source": [
    "# Import model and Test on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDyk5ksCeDOK"
   },
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model('save_models/best_model.hdf5')\n",
    "#best_model.compile(optimizer = tf.keras.optimizers.Nadam(learning_rate=0.0007), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KsMjtRetqLL"
   },
   "outputs": [],
   "source": [
    "test_data_text = '3-[3-(bromomethyl)-4-hydroxyphenyl]propanoic acid'\n",
    "test_data_text_cut = '3|-|[|3|-|(|bromo|meth|yl|)|-|4|-|hydroxy|phen|yl|]|prop|an|oic acid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "id": "WWj1_5XS30p_",
    "outputId": "3c112298-265f-46c5-9c61-83e978083095"
   },
   "outputs": [],
   "source": [
    "_, my_y = create_dataset(test_data_text_cut)\n",
    "myText_test = text_pred_preprocessing(test_data_text)\n",
    "\n",
    "pred_test_proba = best_model.predict(myText_test)\n",
    "\n",
    "pred_test = decode_label(pred_test_proba)\n",
    "pred_test[0] = 1\n",
    "my_y_decode = decode_label(my_y)\n",
    "\n",
    "print(pred_test)\n",
    "#print(my_y_decode)\n",
    "\n",
    "# Count same item between y (label) and pred (prediction)\n",
    "elem_same = (pred_test == my_y_decode).sum()\n",
    "print(\"\\nSame =\",elem_same,\", Not Same =\",pred_test.shape[0]-elem_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "jiGlram741Ne",
    "outputId": "c2c6be58-b055-4218-d889-5888a2742779"
   },
   "outputs": [],
   "source": [
    "words = word_tokenize(test_data_text, pred_test)\n",
    "print(words)\n",
    "print('|'.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6CR383emWEt"
   },
   "source": [
    "# Function Confusion Matrix visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PijmyACBmf0e"
   },
   "source": [
    "# Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "WenTnLTpmp_4",
    "outputId": "9f8d8576-ee8f-46f2-cbe9-63e47d92e79a"
   },
   "outputs": [],
   "source": [
    "from nami.visualize import plot_confusion_matrix\r\n",
    "labels = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\r\n",
    "categories = [\"Zero\", \"One\"]\r\n",
    "plot_confusion_matrix(tf.math.confusion_matrix(my_y_decode, pred_test, num_classes=2).numpy(), \r\n",
    "                      group_names=labels,\r\n",
    "                      categories=categories, cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIFvoxuOZE7J"
   },
   "source": [
    "## BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "k42mTNkqZyA2",
    "outputId": "7186287c-3356-4eb6-85b8-11c56171b62f"
   },
   "outputs": [],
   "source": [
    "reference = test_data_text_cut.split('|')\n",
    "print(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "NTRwxpmRZZKh",
    "outputId": "c3665a2b-ea77-4c45-b0e5-0c33805ddf5e"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "score = nltk.translate.bleu_score.sentence_bleu([reference],words)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "e6CR383emWEt"
   ],
   "machine_shape": "hm",
   "name": "ORG_Chem_Word_Segmentation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}